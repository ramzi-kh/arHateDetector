{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "uzwubvSvSNvZ"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# DATA"
      ],
      "metadata": {
        "id": "QFhWNiQKkbPw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eH4GZ2HXnav-"
      },
      "outputs": [],
      "source": [
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "#df = pd.read_excel(\"/content/levantine.xlsx\", header=0)\n",
        "#df = df.drop(df.loc[df[\"Class\"]==0].sample(frac=0.40).index)\n",
        "\n",
        "#df = pd.read_excel(\"/content/multi.xlsx\", header=0)\n",
        "#df = df.drop(df.loc[df[\"Class\"]==0].sample(frac=0.40).index)\n",
        "\n",
        "#df = pd.read_excel(\"/content/nuha.xlsx\", header=0)\n",
        "\n",
        "#df = pd.read_excel(\"/content/sb.xlsx\", header=0)\n",
        "\n",
        "#df = pd.read_excel(\"/content/raghad_total.xlsx\", header=0)\n",
        "\n",
        "df = pd.read_csv(\"/content/total.csv\", header=0)\n",
        "\n",
        "#df = pd.read_excel(\"/content/aracovid.xlsx\", header=0)\n",
        "#df = df.drop(df.loc[df[\"Class\"]==0].sample(frac=0.68).index)\n",
        "\n",
        "df['Tweet'] = df['Tweet'].astype(str)\n",
        "df['Class'] = df['Class'].astype(int)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df[\"Class\"].value_counts()"
      ],
      "metadata": {
        "id": "lduv2YPVnpcb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4d177a66-e9d3-4def-dc69-f206753a485a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    2676\n",
              "1     823\n",
              "Name: Class, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.isnull().sum().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j23qs0IbEhB7",
        "outputId": "1fad1b55-f7b5-4dbd-de9f-8d3cc1b231cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "id": "jMlCbw73p02u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PREPROCESSING"
      ],
      "metadata": {
        "id": "U1c9ArfqanfA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install pyarabic\n",
        "\n",
        "import re\n",
        "import pyarabic.araby as araby"
      ],
      "metadata": {
        "id": "ZFNQbpY1bHH9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "649fa3ea-ab75-4962-ef26-393362dc1b00"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pyarabic\n",
            "  Downloading PyArabic-0.6.15-py3-none-any.whl (126 kB)\n",
            "\u001b[K     |████████████████████████████████| 126 kB 6.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.8/dist-packages (from pyarabic) (1.15.0)\n",
            "Installing collected packages: pyarabic\n",
            "Successfully installed pyarabic-0.6.15\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip  install -U farasapy"
      ],
      "metadata": {
        "id": "dx5tNjIHgyoS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "28b7244e-b649-47ec-e4ca-6d7f3c0a3ccd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting farasapy\n",
            "  Downloading farasapy-0.0.14-py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from farasapy) (2.23.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from farasapy) (4.64.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->farasapy) (2022.9.24)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->farasapy) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->farasapy) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->farasapy) (3.0.4)\n",
            "Installing collected packages: farasapy\n",
            "Successfully installed farasapy-0.0.14\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import re\n",
        "from farasa.stemmer import FarasaStemmer\n",
        "\n",
        "\n",
        "stopwords = {\"،\",\"آض\",\"آمينَ\",\"آه\",\"آهاً\",\"آي\",\"أ\",\"أب\",\"أجل\",\"أجمع\",\"أخ\",\"أخذ\",\"أصبح\",\"أضحى\",\"أقبل\",\"أقل\",\"أكثر\",\"ألا\",\"أم\",\"أما\",\"أمامك\",\"أمامكَ\",\"أمسى\",\"أمّا\",\"أن\",\"أنا\",\"أنت\",\"أنتم\",\"أنتما\",\"أنتن\",\"أنتِ\",\"أنشأ\",\"أنّى\",\"أو\",\"أوشك\",\"أولئك\",\"أولئكم\",\"أولاء\",\"أولالك\",\"أوّهْ\",\"أي\",\"أيا\",\"أين\",\"أينما\",\"أيّ\",\"أَنَّ\",\"أََيُّ\",\"أُفٍّ\",\"إذ\",\"إذا\",\"إذاً\",\"إذما\",\"إذن\",\"إلى\",\"إليكم\",\"إليكما\",\"إليكنّ\",\"إليكَ\",\"إلَيْكَ\",\"إلّا\",\"إمّا\",\"إن\",\"إنّما\",\"إي\",\"إياك\",\"إياكم\",\"إياكما\",\"إياكن\",\"إيانا\",\"إياه\",\"إياها\",\"إياهم\",\"إياهما\",\"إياهن\",\"إياي\",\"إيهٍ\",\"إِنَّ\",\"ا\",\"ابتدأ\",\"اثر\",\"اجل\",\"احد\",\"اخرى\",\"اخلولق\",\"اذا\",\"اربعة\",\"ارتدّ\",\"استحال\",\"اطار\",\"اعادة\",\"اعلنت\",\"اف\",\"اكثر\",\"اكد\",\"الألاء\",\"الألى\",\"الا\",\"الاخيرة\",\"الان\",\"الاول\",\"الاولى\",\"التى\",\"التي\",\"الثاني\",\"الثانية\",\"الذاتي\",\"الذى\",\"الذي\",\"الذين\",\"السابق\",\"الف\",\"اللائي\",\"اللاتي\",\"اللتان\",\"اللتيا\",\"اللتين\",\"اللذان\",\"اللذين\",\"اللواتي\",\"الماضي\",\"المقبل\",\"الوقت\",\"الى\",\"اليوم\",\"اما\",\"امام\",\"امس\",\"ان\",\"انبرى\",\"انقلب\",\"انه\",\"انها\",\"او\",\"اول\",\"اي\",\"ايار\",\"ايام\",\"ايضا\",\"ب\",\"بات\",\"باسم\",\"بان\",\"بخٍ\",\"برس\",\"بسبب\",\"بسّ\",\"بشكل\",\"بضع\",\"بطآن\",\"بعد\",\"بعض\",\"بك\",\"بكم\",\"بكما\",\"بكن\",\"بل\",\"بلى\",\"بما\",\"بماذا\",\"بمن\",\"بن\",\"بنا\",\"به\",\"بها\",\"بي\",\"بيد\",\"بين\",\"بَسْ\",\"بَلْهَ\",\"بِئْسَ\",\"تانِ\",\"تانِك\",\"تبدّل\",\"تجاه\",\"تحوّل\",\"تلقاء\",\"تلك\",\"تلكم\",\"تلكما\",\"تم\",\"تينك\",\"تَيْنِ\",\"تِه\",\"تِي\",\"ثلاثة\",\"ثم\",\"ثمّ\",\"ثمّة\",\"ثُمَّ\",\"جعل\",\"جلل\",\"جميع\",\"جير\",\"حار\",\"حاشا\",\"حاليا\",\"حاي\",\"حتى\",\"حرى\",\"حسب\",\"حم\",\"حوالى\",\"حول\",\"حيث\",\"حيثما\",\"حين\",\"حيَّ\",\"حَبَّذَا\",\"حَتَّى\",\"حَذارِ\",\"خلا\",\"خلال\",\"دون\",\"دونك\",\"ذا\",\"ذات\",\"ذاك\",\"ذانك\",\"ذانِ\",\"ذلك\",\"ذلكم\",\"ذلكما\",\"ذلكن\",\"ذو\",\"ذوا\",\"ذواتا\",\"ذواتي\",\"ذيت\",\"ذينك\",\"ذَيْنِ\",\"ذِه\",\"ذِي\",\"راح\",\"رجع\",\"رويدك\",\"ريث\",\"رُبَّ\",\"زيارة\",\"سبحان\",\"سرعان\",\"سنة\",\"سنوات\",\"سوف\",\"سوى\",\"سَاءَ\",\"سَاءَمَا\",\"شبه\",\"شخصا\",\"شرع\",\"شَتَّانَ\",\"صار\",\"صباح\",\"صفر\",\"صهٍ\",\"صهْ\",\"ضد\",\"ضمن\",\"طاق\",\"طالما\",\"طفق\",\"طَق\",\"ظلّ\",\"عاد\",\"عام\",\"عاما\",\"عامة\",\"عدا\",\"عدة\",\"عدد\",\"عدم\",\"عسى\",\"عشر\",\"عشرة\",\"علق\",\"على\",\"عليك\",\"عليه\",\"عليها\",\"علًّ\",\"عن\",\"عند\",\"عندما\",\"عوض\",\"عين\",\"عَدَسْ\",\"عَمَّا\",\"غدا\",\"غير\",\"ـ\",\"ف\",\"فان\",\"فلان\",\"فو\",\"فى\",\"في\",\"فيم\",\"فيما\",\"فيه\",\"فيها\",\"قال\",\"قام\",\"قبل\",\"قد\",\"قطّ\",\"قلما\",\"قوة\",\"كأنّما\",\"كأين\",\"كأيّ\",\"كأيّن\",\"كاد\",\"كان\",\"كانت\",\"كذا\",\"كذلك\",\"كرب\",\"كل\",\"كلا\",\"كلاهما\",\"كلتا\",\"كلم\",\"كليكما\",\"كليهما\",\"كلّما\",\"كلَّا\",\"كم\",\"كما\",\"كي\",\"كيت\",\"كيف\",\"كيفما\",\"كَأَنَّ\",\"كِخ\",\"لئن\",\"لا\",\"لات\",\"لاسيما\",\"لدن\",\"لدى\",\"لعمر\",\"لقاء\",\"لك\",\"لكم\",\"لكما\",\"لكن\",\"لكنَّما\",\"لكي\",\"لكيلا\",\"للامم\",\"لم\",\"لما\",\"لمّا\",\"لن\",\"لنا\",\"له\",\"لها\",\"لو\",\"لوكالة\",\"لولا\",\"لوما\",\"لي\",\"لَسْتَ\",\"لَسْتُ\",\"لَسْتُم\",\"لَسْتُمَا\",\"لَسْتُنَّ\",\"لَسْتِ\",\"لَسْنَ\",\"لَعَلَّ\",\"لَكِنَّ\",\"لَيْتَ\",\"لَيْسَ\",\"لَيْسَا\",\"لَيْسَتَا\",\"لَيْسَتْ\",\"لَيْسُوا\",\"لَِسْنَا\",\"ما\",\"ماانفك\",\"مابرح\",\"مادام\",\"ماذا\",\"مازال\",\"مافتئ\",\"مايو\",\"متى\",\"مثل\",\"مذ\",\"مساء\",\"مع\",\"معاذ\",\"مقابل\",\"مكانكم\",\"مكانكما\",\"مكانكنّ\",\"مكانَك\",\"مليار\",\"مليون\",\"مما\",\"ممن\",\"من\",\"منذ\",\"منها\",\"مه\",\"مهما\",\"مَنْ\",\"مِن\",\"نحن\",\"نحو\",\"نعم\",\"نفس\",\"نفسه\",\"نهاية\",\"نَخْ\",\"نِعِمّا\",\"نِعْمَ\",\"ها\",\"هاؤم\",\"هاكَ\",\"هاهنا\",\"هبّ\",\"هذا\",\"هذه\",\"هكذا\",\"هل\",\"هلمَّ\",\"هلّا\",\"هم\",\"هما\",\"هن\",\"هنا\",\"هناك\",\"هنالك\",\"هو\",\"هي\",\"هيا\",\"هيت\",\"هيّا\",\"هَؤلاء\",\"هَاتانِ\",\"هَاتَيْنِ\",\"هَاتِه\",\"هَاتِي\",\"هَجْ\",\"هَذا\",\"هَذانِ\",\"هَذَيْنِ\",\"هَذِه\",\"هَذِي\",\"هَيْهَاتَ\",\"و\",\"و6\",\"وا\",\"واحد\",\"واضاف\",\"واضافت\",\"واكد\",\"وان\",\"واهاً\",\"واوضح\",\"وراءَك\",\"وفي\",\"وقال\",\"وقالت\",\"وقد\",\"وقف\",\"وكان\",\"وكانت\",\"ولا\",\"ولم\",\"ومن\",\"مَن\",\"وهو\",\"وهي\",\"ويكأنّ\",\"وَيْ\",\"وُشْكَانََ\",\"يكون\",\"يمكن\",\"يوم\",\"ّأيّان\"}\n",
        "\n",
        "def remove_tashkeel(text):\n",
        "    return araby.strip_tashkeel(text)\n",
        "\n",
        "def remove_tatweel(text):\n",
        "    return araby.strip_tatweel(text)\n",
        "\n",
        "def normalization(text):\n",
        "    text = re.sub(\"[إأٱآا]\", \"ا\", text)\n",
        "    text = re.sub(\"ي\", \"ى\", text)\n",
        "    text = re.sub(\"ة\", \"ه\", text)\n",
        "    return text\n",
        "\n",
        "def normalize_hamza(text):\n",
        "    return araby.normalize_hamza(text)\n",
        "\n",
        "def remove_usernames(text):\n",
        "    text = re.sub(\"@[\\w]*\", '', text)\n",
        "    return text\n",
        "\n",
        "def remove_hashtags(text):\n",
        "    text = re.sub(\"#[\\w]*\", '', text)\n",
        "    return text\n",
        "\n",
        "def clean_text(text):\n",
        "    text = re.sub(r'[.,\\\"،\\/#!$%\\^&\\*;:{}=\\-_`~()?؟﴾﴿]',' ',text) #remove punctuation\n",
        "    text = re.sub('#\\d+K\\d+', ' ', text)  # years like 2K19\n",
        "    text = re.sub('http\\S+\\s*', ' ', text)  # remove URLs\n",
        "    text = re.sub('RT|cc', ' ', text)  # remove RT and cc\n",
        "    text = re.sub(r'[0-9]+',' ',text) #remove numbers\n",
        "    text = re.sub(r'[\\u0660-\\u0669]+',' ',text) #remove arabic numbers\n",
        "    text = re.sub(r\"_\",' ',text) #remove _\n",
        "    text = re.sub('\\s+', ' ', text).strip() #remove additional whitespaces\n",
        "    return text\n",
        "\n",
        "def remove_non_arabic_letters(text):\n",
        "    ENGLISH_CHARS =r'[a-zA-Z]+\\b(?<!urllink|mention)'\n",
        "    text = re.sub(ENGLISH_CHARS, \"\",  text)\n",
        "    return text\n",
        "\n",
        "def remove_stopwords(text, stopwords):\n",
        "    word_list = text.split(' ')\n",
        "    filtered_words = [word for word in word_list if word not in stopwords]\n",
        "    text = ' '.join(filtered_words)\n",
        "    return text\n",
        "\n",
        "def remove_imoji(text):\n",
        "\n",
        "    emoji_pattern = re.compile(\"[\"\n",
        "                                    u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
        "                                    u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
        "                                    u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
        "                                    u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
        "                                    u\"\\U00002702-\\U000027B0\"\n",
        "                                    u\"\\U000024C2-\\U0001F251\"\n",
        "                                    \"]+\", flags=re.UNICODE)\n",
        "    text = re.sub(emoji_pattern, '', text)\n",
        "    return text\n",
        "\n",
        "#stemmer = FarasaStemmer()\n",
        "\n",
        "\n",
        "\n",
        "def clean_tweets(df):\n",
        "\n",
        "  tempArr = []\n",
        "  for line in df:\n",
        "\n",
        "    tweet = remove_tashkeel(line)\n",
        "    tweet = remove_tatweel(tweet)\n",
        "    tweet = normalization(tweet)\n",
        "    tweet = normalize_hamza(tweet)\n",
        "    tweet = remove_usernames(tweet)\n",
        "    tweet = remove_hashtags(tweet)\n",
        "    tweet = remove_non_arabic_letters(tweet)\n",
        "    tweet = remove_stopwords(tweet, stopwords)\n",
        "    tweet = remove_imoji(tweet)\n",
        "    tweet = clean_text(tweet)\n",
        "    #tweet = stemmer.stem(tweet)\n",
        "\n",
        "    tempArr.append(tweet)\n",
        "  return tempArr\n"
      ],
      "metadata": {
        "id": "cLTt9qiyam4V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# clean data\n",
        "\n",
        "clean = clean_tweets(df[\"Tweet\"])\n",
        "clean = pd.DataFrame(clean)\n",
        "\n",
        "df[\"Tweet\"] = clean\n",
        "df['Tweet'] = df['Tweet'].astype(str)"
      ],
      "metadata": {
        "id": "fh0YKS7Pg-g9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.rename(columns={'Tweet':'texts'}, inplace=True)\n",
        "df.rename(columns={'Class':'data_labels'}, inplace=True)"
      ],
      "metadata": {
        "id": "CwJJZHWNujeI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# DATA PARTITION"
      ],
      "metadata": {
        "id": "HCzwqlxha3uR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X = df.texts.values\n",
        "Y = df.data_labels.values\n",
        "\n",
        "X_train, X_val, Y_train, Y_val =train_test_split(X, Y, test_size=0.25, random_state=200)"
      ],
      "metadata": {
        "id": "i4X2CAewuoQi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CNN & RESULTS"
      ],
      "metadata": {
        "id": "Z_zl1MtskRK0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## LEVANTINE"
      ],
      "metadata": {
        "id": "MqelJUJgkkxp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras import layers\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras_preprocessing.sequence import pad_sequences\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "tokenizer = Tokenizer(num_words=5000)\n",
        "tokenizer.fit_on_texts(X_train)\n",
        "\n",
        "X_train = tokenizer.texts_to_sequences(X_train)\n",
        "X_val = tokenizer.texts_to_sequences(X_val)\n",
        "\n",
        "\n",
        "vocab_size = len(tokenizer.word_index) + 1  # Adding 1 because of reserved 0 index\n",
        "\n",
        "embedding_dim = 100\n",
        "maxlen = 100\n",
        "\n",
        "X_train = pad_sequences(X_train, padding='post', maxlen=maxlen)\n",
        "X_val = pad_sequences(X_val, padding='post', maxlen=maxlen)\n",
        "\n",
        "\n",
        "model = Sequential()\n",
        "model.add(layers.Embedding(vocab_size, embedding_dim, input_length=maxlen))\n",
        "model.add(layers.Conv1D(128, 5, activation='relu'))\n",
        "model.add(layers.GlobalMaxPooling1D())\n",
        "\n",
        "model.add(layers.Dense(10, activation='relu'))\n",
        "model.add(layers.Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "\n",
        "model.summary()\n",
        "\n",
        "#X_train = np.asarray(X_train).astype('float32')\n",
        "#X_val = np.asarray(X_val).astype('float32')\n",
        "\n",
        "history = model.fit(X_train, Y_train,\n",
        "                    epochs=10,\n",
        "                    verbose=False,\n",
        "                    validation_data=(X_val, Y_val),\n",
        "                    batch_size=10)\n",
        "\n",
        "loss, accuracy = model.evaluate(X_train, Y_train, verbose=False)\n",
        "print(\"Training Accuracy: {:.4f}\".format(accuracy))\n",
        "loss, accuracy = model.evaluate(X_val, Y_val, verbose=False)\n",
        "print(\"Testing Accuracy:  {:.4f}\".format(accuracy))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MU9OAyKcYM7-",
        "outputId": "112a7ae0-da21-4c5d-c18f-b6c5d853e06c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_1 (Embedding)     (None, 100, 100)          1616100   \n",
            "                                                                 \n",
            " conv1d_1 (Conv1D)           (None, 96, 128)           64128     \n",
            "                                                                 \n",
            " global_max_pooling1d_1 (Glo  (None, 128)              0         \n",
            " balMaxPooling1D)                                                \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 10)                1290      \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 1)                 11        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,681,529\n",
            "Trainable params: 1,681,529\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Training Accuracy: 0.9941\n",
            "Testing Accuracy:  0.8222\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## MULTI"
      ],
      "metadata": {
        "id": "IJIpx2-9ko8O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "tokenizer = Tokenizer(num_words=5000)\n",
        "tokenizer.fit_on_texts(X_train)\n",
        "\n",
        "X_train = tokenizer.texts_to_sequences(X_train)\n",
        "X_val = tokenizer.texts_to_sequences(X_val)\n",
        "\n",
        "\n",
        "vocab_size = len(tokenizer.word_index) + 1  # Adding 1 because of reserved 0 index\n",
        "\n",
        "embedding_dim = 100\n",
        "maxlen = 100\n",
        "\n",
        "X_train = pad_sequences(X_train, padding='post', maxlen=maxlen)\n",
        "X_val = pad_sequences(X_val, padding='post', maxlen=maxlen)\n",
        "\n",
        "\n",
        "model = Sequential()\n",
        "model.add(layers.Embedding(vocab_size, embedding_dim, input_length=maxlen))\n",
        "model.add(layers.Conv1D(128, 5, activation='relu'))\n",
        "model.add(layers.GlobalMaxPooling1D())\n",
        "\n",
        "model.add(layers.Dense(10, activation='relu'))\n",
        "model.add(layers.Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "\n",
        "model.summary()\n",
        "\n",
        "#X_train = np.asarray(X_train).astype('float32')\n",
        "#X_val = np.asarray(X_val).astype('float32')\n",
        "\n",
        "history = model.fit(X_train, Y_train,\n",
        "                    epochs=10,\n",
        "                    verbose=False,\n",
        "                    validation_data=(X_val, Y_val),\n",
        "                    batch_size=10)\n",
        "\n",
        "loss, accuracy = model.evaluate(X_train, Y_train, verbose=False)\n",
        "print(\"Training Accuracy: {:.4f}\".format(accuracy))\n",
        "loss, accuracy = model.evaluate(X_val, Y_val, verbose=False)\n",
        "print(\"Testing Accuracy:  {:.4f}\".format(accuracy))\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8wpi2a4OnbRf",
        "outputId": "47308581-50e4-4ac8-806e-3f8e83458ea0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_2 (Embedding)     (None, 100, 100)          1369500   \n",
            "                                                                 \n",
            " conv1d_2 (Conv1D)           (None, 96, 128)           64128     \n",
            "                                                                 \n",
            " global_max_pooling1d_2 (Glo  (None, 128)              0         \n",
            " balMaxPooling1D)                                                \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 10)                1290      \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 1)                 11        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,434,929\n",
            "Trainable params: 1,434,929\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Training Accuracy: 0.9954\n",
            "Testing Accuracy:  0.7907\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## NUHA"
      ],
      "metadata": {
        "id": "DquIK6V3kujX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "tokenizer = Tokenizer(num_words=5000)\n",
        "tokenizer.fit_on_texts(X_train)\n",
        "\n",
        "X_train = tokenizer.texts_to_sequences(X_train)\n",
        "X_val = tokenizer.texts_to_sequences(X_val)\n",
        "\n",
        "\n",
        "vocab_size = len(tokenizer.word_index) + 1  # Adding 1 because of reserved 0 index\n",
        "\n",
        "embedding_dim = 100\n",
        "maxlen = 100\n",
        "\n",
        "X_train = pad_sequences(X_train, padding='post', maxlen=maxlen)\n",
        "X_val = pad_sequences(X_val, padding='post', maxlen=maxlen)\n",
        "\n",
        "\n",
        "model = Sequential()\n",
        "model.add(layers.Embedding(vocab_size, embedding_dim, input_length=maxlen))\n",
        "model.add(layers.Conv1D(128, 5, activation='relu'))\n",
        "model.add(layers.GlobalMaxPooling1D())\n",
        "\n",
        "model.add(layers.Dense(10, activation='relu'))\n",
        "model.add(layers.Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "\n",
        "model.summary()\n",
        "\n",
        "#X_train = np.asarray(X_train).astype('float32')\n",
        "#X_val = np.asarray(X_val).astype('float32')\n",
        "\n",
        "history = model.fit(X_train, Y_train,\n",
        "                    epochs=10,\n",
        "                    verbose=False,\n",
        "                    validation_data=(X_val, Y_val),\n",
        "                    batch_size=10)\n",
        "\n",
        "loss, accuracy = model.evaluate(X_train, Y_train, verbose=False)\n",
        "print(\"Training Accuracy: {:.4f}\".format(accuracy))\n",
        "loss, accuracy = model.evaluate(X_val, Y_val, verbose=False)\n",
        "print(\"Testing Accuracy:  {:.4f}\".format(accuracy))\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V0E_Eyy6n7ZA",
        "outputId": "44d921bf-73fa-47da-a69e-763a388150d9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_3 (Embedding)     (None, 100, 100)          1696200   \n",
            "                                                                 \n",
            " conv1d_3 (Conv1D)           (None, 96, 128)           64128     \n",
            "                                                                 \n",
            " global_max_pooling1d_3 (Glo  (None, 128)              0         \n",
            " balMaxPooling1D)                                                \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 10)                1290      \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 1)                 11        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,761,629\n",
            "Trainable params: 1,761,629\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Training Accuracy: 0.9792\n",
            "Testing Accuracy:  0.7577\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## SB"
      ],
      "metadata": {
        "id": "DR7oBNlKkyKM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "tokenizer = Tokenizer(num_words=5000)\n",
        "tokenizer.fit_on_texts(X_train)\n",
        "\n",
        "X_train = tokenizer.texts_to_sequences(X_train)\n",
        "X_val = tokenizer.texts_to_sequences(X_val)\n",
        "\n",
        "\n",
        "vocab_size = len(tokenizer.word_index) + 1  # Adding 1 because of reserved 0 index\n",
        "\n",
        "embedding_dim = 100\n",
        "maxlen = 100\n",
        "\n",
        "X_train = pad_sequences(X_train, padding='post', maxlen=maxlen)\n",
        "X_val = pad_sequences(X_val, padding='post', maxlen=maxlen)\n",
        "\n",
        "\n",
        "model = Sequential()\n",
        "model.add(layers.Embedding(vocab_size, embedding_dim, input_length=maxlen))\n",
        "model.add(layers.Conv1D(128, 5, activation='relu'))\n",
        "model.add(layers.GlobalMaxPooling1D())\n",
        "\n",
        "model.add(layers.Dense(10, activation='relu'))\n",
        "model.add(layers.Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "\n",
        "model.summary()\n",
        "\n",
        "#X_train = np.asarray(X_train).astype('float32')\n",
        "#X_val = np.asarray(X_val).astype('float32')\n",
        "\n",
        "history = model.fit(X_train, Y_train,\n",
        "                    epochs=10,\n",
        "                    verbose=False,\n",
        "                    validation_data=(X_val, Y_val),\n",
        "                    batch_size=10)\n",
        "\n",
        "loss, accuracy = model.evaluate(X_train, Y_train, verbose=False)\n",
        "print(\"Training Accuracy: {:.4f}\".format(accuracy))\n",
        "loss, accuracy = model.evaluate(X_val, Y_val, verbose=False)\n",
        "print(\"Testing Accuracy:  {:.4f}\".format(accuracy))\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "JQOy8QmNofs7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "685048f2-308f-41d6-b089-43f44053a077"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_5 (Embedding)     (None, 100, 100)          1767500   \n",
            "                                                                 \n",
            " conv1d_5 (Conv1D)           (None, 96, 128)           64128     \n",
            "                                                                 \n",
            " global_max_pooling1d_5 (Glo  (None, 128)              0         \n",
            " balMaxPooling1D)                                                \n",
            "                                                                 \n",
            " dense_10 (Dense)            (None, 10)                1290      \n",
            "                                                                 \n",
            " dense_11 (Dense)            (None, 1)                 11        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,832,929\n",
            "Trainable params: 1,832,929\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Training Accuracy: 0.9996\n",
            "Testing Accuracy:  0.8392\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## RAGHAD"
      ],
      "metadata": {
        "id": "_ApatZhkk1u6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "tokenizer = Tokenizer(num_words=5000)\n",
        "tokenizer.fit_on_texts(X_train)\n",
        "\n",
        "X_train = tokenizer.texts_to_sequences(X_train)\n",
        "X_val = tokenizer.texts_to_sequences(X_val)\n",
        "\n",
        "\n",
        "vocab_size = len(tokenizer.word_index) + 1  # Adding 1 because of reserved 0 index\n",
        "\n",
        "embedding_dim = 100\n",
        "maxlen = 100\n",
        "\n",
        "X_train = pad_sequences(X_train, padding='post', maxlen=maxlen)\n",
        "X_val = pad_sequences(X_val, padding='post', maxlen=maxlen)\n",
        "\n",
        "\n",
        "model = Sequential()\n",
        "model.add(layers.Embedding(vocab_size, embedding_dim, input_length=maxlen))\n",
        "model.add(layers.Conv1D(128, 5, activation='relu'))\n",
        "model.add(layers.GlobalMaxPooling1D())\n",
        "\n",
        "model.add(layers.Dense(10, activation='relu'))\n",
        "model.add(layers.Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "\n",
        "model.summary()\n",
        "\n",
        "#X_train = np.asarray(X_train).astype('float32')\n",
        "#X_val = np.asarray(X_val).astype('float32')\n",
        "\n",
        "history = model.fit(X_train, Y_train,\n",
        "                    epochs=10,\n",
        "                    verbose=False,\n",
        "                    validation_data=(X_val, Y_val),\n",
        "                    batch_size=10)\n",
        "\n",
        "loss, accuracy = model.evaluate(X_train, Y_train, verbose=False)\n",
        "print(\"Training Accuracy: {:.4f}\".format(accuracy))\n",
        "loss, accuracy = model.evaluate(X_val, Y_val, verbose=False)\n",
        "print(\"Testing Accuracy:  {:.4f}\".format(accuracy))\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gc6sMVr1qXtI",
        "outputId": "b32ee922-f302-4aec-b2a7-f8bc3c8cb028"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_6 (Embedding)     (None, 100, 100)          2664000   \n",
            "                                                                 \n",
            " conv1d_6 (Conv1D)           (None, 96, 128)           64128     \n",
            "                                                                 \n",
            " global_max_pooling1d_6 (Glo  (None, 128)              0         \n",
            " balMaxPooling1D)                                                \n",
            "                                                                 \n",
            " dense_12 (Dense)            (None, 10)                1290      \n",
            "                                                                 \n",
            " dense_13 (Dense)            (None, 1)                 11        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,729,429\n",
            "Trainable params: 2,729,429\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Training Accuracy: 0.9953\n",
            "Testing Accuracy:  0.7780\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ARACOVID"
      ],
      "metadata": {
        "id": "8Gul9McOk6VS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "tokenizer = Tokenizer(num_words=5000)\n",
        "tokenizer.fit_on_texts(X_train)\n",
        "\n",
        "X_train = tokenizer.texts_to_sequences(X_train)\n",
        "X_val = tokenizer.texts_to_sequences(X_val)\n",
        "\n",
        "\n",
        "vocab_size = len(tokenizer.word_index) + 1  # Adding 1 because of reserved 0 index\n",
        "\n",
        "embedding_dim = 100\n",
        "maxlen = 100\n",
        "\n",
        "X_train = pad_sequences(X_train, padding='post', maxlen=maxlen)\n",
        "X_val = pad_sequences(X_val, padding='post', maxlen=maxlen)\n",
        "\n",
        "\n",
        "model = Sequential()\n",
        "model.add(layers.Embedding(vocab_size, embedding_dim, input_length=maxlen))\n",
        "model.add(layers.Conv1D(128, 5, activation='relu'))\n",
        "model.add(layers.GlobalMaxPooling1D())\n",
        "\n",
        "model.add(layers.Dense(10, activation='relu'))\n",
        "model.add(layers.Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "\n",
        "model.summary()\n",
        "\n",
        "#X_train = np.asarray(X_train).astype('float32')\n",
        "#X_val = np.asarray(X_val).astype('float32')\n",
        "\n",
        "history = model.fit(X_train, Y_train,\n",
        "                    epochs=10,\n",
        "                    verbose=False,\n",
        "                    validation_data=(X_val, Y_val),\n",
        "                    batch_size=10)\n",
        "\n",
        "loss, accuracy = model.evaluate(X_train, Y_train, verbose=False)\n",
        "print(\"Training Accuracy: {:.4f}\".format(accuracy))\n",
        "loss, accuracy = model.evaluate(X_val, Y_val, verbose=False)\n",
        "print(\"Testing Accuracy:  {:.4f}\".format(accuracy))\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m5JZQ2QlrKwS",
        "outputId": "ebcfc95b-e1e3-4ab4-f079-702a74f1cb81"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_9\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_9 (Embedding)     (None, 100, 100)          664700    \n",
            "                                                                 \n",
            " conv1d_9 (Conv1D)           (None, 96, 128)           64128     \n",
            "                                                                 \n",
            " global_max_pooling1d_9 (Glo  (None, 128)              0         \n",
            " balMaxPooling1D)                                                \n",
            "                                                                 \n",
            " dense_18 (Dense)            (None, 10)                1290      \n",
            "                                                                 \n",
            " dense_19 (Dense)            (None, 1)                 11        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 730,129\n",
            "Trainable params: 730,129\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Training Accuracy: 0.8449\n",
            "Testing Accuracy:  0.7531\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## TOTAL"
      ],
      "metadata": {
        "id": "u7ptz0Rfk_8o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "tokenizer = Tokenizer(num_words=5000)\n",
        "tokenizer.fit_on_texts(X_train)\n",
        "\n",
        "X_train = tokenizer.texts_to_sequences(X_train)\n",
        "X_val = tokenizer.texts_to_sequences(X_val)\n",
        "\n",
        "\n",
        "vocab_size = len(tokenizer.word_index) + 1  # Adding 1 because of reserved 0 index\n",
        "\n",
        "embedding_dim = 100\n",
        "maxlen = 100\n",
        "\n",
        "X_train = pad_sequences(X_train, padding='post', maxlen=maxlen)\n",
        "X_val = pad_sequences(X_val, padding='post', maxlen=maxlen)\n",
        "\n",
        "\n",
        "model = Sequential()\n",
        "model.add(layers.Embedding(vocab_size, embedding_dim, input_length=maxlen))\n",
        "model.add(layers.Conv1D(128, 5, activation='relu'))\n",
        "model.add(layers.GlobalMaxPooling1D())\n",
        "\n",
        "model.add(layers.Dense(10, activation='relu'))\n",
        "model.add(layers.Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "\n",
        "model.summary()\n",
        "\n",
        "#X_train = np.asarray(X_train).astype('float32')\n",
        "#X_val = np.asarray(X_val).astype('float32')\n",
        "\n",
        "history = model.fit(X_train, Y_train,\n",
        "                    epochs=10,\n",
        "                    verbose=False,\n",
        "                    validation_data=(X_val, Y_val),\n",
        "                    batch_size=10)\n",
        "\n",
        "loss, accuracy = model.evaluate(X_train, Y_train, verbose=False)\n",
        "print(\"Training Accuracy: {:.4f}\".format(accuracy))\n",
        "loss, accuracy = model.evaluate(X_val, Y_val, verbose=False)\n",
        "print(\"Testing Accuracy:  {:.4f}\".format(accuracy))\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WStnjlpLtFpO",
        "outputId": "bde0884f-2dac-48bd-d79d-de140b2b4f96"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_10\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_10 (Embedding)    (None, 100, 100)          7044700   \n",
            "                                                                 \n",
            " conv1d_10 (Conv1D)          (None, 96, 128)           64128     \n",
            "                                                                 \n",
            " global_max_pooling1d_10 (Gl  (None, 128)              0         \n",
            " obalMaxPooling1D)                                               \n",
            "                                                                 \n",
            " dense_20 (Dense)            (None, 10)                1290      \n",
            "                                                                 \n",
            " dense_21 (Dense)            (None, 1)                 11        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 7,110,129\n",
            "Trainable params: 7,110,129\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Training Accuracy: 0.9874\n",
            "Testing Accuracy:  0.8765\n"
          ]
        }
      ]
    }
  ]
}